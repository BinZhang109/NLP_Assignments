{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aymericdamien/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hell World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Simple hello world using TensorFlow\n",
    "\n",
    "# Create a Constant op\n",
    "# The op is added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tf session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "# Run graph\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic constant operations\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 2 b: 3\n",
      "Addition with constants: 5\n",
      "Multiplication with constants: 6\n"
     ]
    }
   ],
   "source": [
    "# Launch the default graph.\n",
    "with tf.Session() as sess:\n",
    "    print(\"a: %i\" % sess.run(a), \"b: %i\" % sess.run(b))\n",
    "    print(\"Addition with constants: %i\" % sess.run(a+b))\n",
    "    print(\"Multiplication with constants: %i\" % sess.run(a*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations with variable as graph input\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Variable op. (define as input when running session)\n",
    "# tf Graph input\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some operations\n",
    "add = tf.add(a, b)\n",
    "mul = tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition with variables: 5\n",
      "Multiplication with variables: 6\n"
     ]
    }
   ],
   "source": [
    "# Launch the default graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run every operation with variable input\n",
    "    print(\"Addition with variables: %i\" % sess.run(add, feed_dict={a: 2, b: 3}))\n",
    "    print(\"Multiplication with variables: %i\" % sess.run(mul, feed_dict={a: 2, b: 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# More in details:\n",
    "# Matrix Multiplication from TensorFlow official tutorial\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "# To run the matmul op we call the session 'run()' method, passing 'product'\n",
    "# which represents the output of the matmul op.  This indicates to the call\n",
    "# that we want to get the output of the matmul op back.\n",
    "#\n",
    "# All inputs needed by the op are run automatically by the session.  They\n",
    "# typically are run in parallel.\n",
    "#\n",
    "# The call 'run(product)' thus causes the execution of threes ops in the\n",
    "# graph: the two constants and matmul.\n",
    "#\n",
    "# The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Eager API basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Eager mode...\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Eager API\n",
    "print(\"Setting Eager mode...\")\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define constant tensors\n",
      "a = 2\n",
      "b = 3\n"
     ]
    }
   ],
   "source": [
    "# Define constant tensors\n",
    "print(\"Define constant tensors\")\n",
    "a = tf.constant(2)\n",
    "print(\"a = %i\" % a)\n",
    "b = tf.constant(3)\n",
    "print(\"b = %i\" % b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running operations, without tf.Session\n",
      "a + b = 5\n",
      "a * b = 6\n"
     ]
    }
   ],
   "source": [
    "# Run the operation without the need for tf.Session\n",
    "print(\"Running operations, without tf.Session\")\n",
    "c = a + b\n",
    "print(\"a + b = %i\" % c)\n",
    "d = a * b\n",
    "print(\"a * b = %i\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixing operations with Tensors and Numpy Arrays\n",
      "Tensor:\n",
      " a = tf.Tensor(\n",
      "[[2. 1.]\n",
      " [1. 0.]], shape=(2, 2), dtype=float32)\n",
      "NumpyArray:\n",
      " b = [[3. 0.]\n",
      " [5. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Full compatibility with Numpy\n",
    "print(\"Mixing operations with Tensors and Numpy Arrays\")\n",
    "\n",
    "# Define constant tensors\n",
    "a = tf.constant([[2., 1.],\n",
    "                 [1., 0.]], dtype=tf.float32)\n",
    "print(\"Tensor:\\n a = %s\" % a)\n",
    "b = np.array([[3., 0.],\n",
    "              [5., 1.]], dtype=np.float32)\n",
    "print(\"NumpyArray:\\n b = %s\" % b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running operations, without tf.Session\n",
      "a + b = tf.Tensor(\n",
      "[[5. 1.]\n",
      " [6. 1.]], shape=(2, 2), dtype=float32)\n",
      "a * b = tf.Tensor(\n",
      "[[11.  1.]\n",
      " [ 3.  0.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Run the operation without the need for tf.Session\n",
    "print(\"Running operations, without tf.Session\")\n",
    "\n",
    "c = a + b\n",
    "print(\"a + b = %s\" % c)\n",
    "\n",
    "d = tf.matmul(a, b)\n",
    "print(\"a * b = %s\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate through Tensor 'a':\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Iterate through Tensor 'a':\")\n",
    "for i in range(a.shape[0]):\n",
    "    for j in range(a.shape[1]):\n",
    "        print(a[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "rng = numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ryan Wu\\Anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.106208548 W= 0.34528488 b= 0.113070354\n",
      "Epoch: 0100 cost= 0.102828495 W= 0.33959362 b= 0.15401246\n",
      "Epoch: 0150 cost= 0.099838980 W= 0.33424088 b= 0.19251956\n",
      "Epoch: 0200 cost= 0.097194940 W= 0.3292066 b= 0.22873661\n",
      "Epoch: 0250 cost= 0.094856493 W= 0.3244716 b= 0.26279962\n",
      "Epoch: 0300 cost= 0.092788309 W= 0.32001814 b= 0.29483697\n",
      "Epoch: 0350 cost= 0.090959176 W= 0.31582972 b= 0.32496876\n",
      "Epoch: 0400 cost= 0.089341559 W= 0.31189027 b= 0.35330805\n",
      "Epoch: 0450 cost= 0.087910898 W= 0.3081852 b= 0.37996247\n",
      "Epoch: 0500 cost= 0.086645663 W= 0.30470034 b= 0.4050318\n",
      "Epoch: 0550 cost= 0.085526802 W= 0.30142298 b= 0.4286092\n",
      "Epoch: 0600 cost= 0.084537305 W= 0.29834047 b= 0.45078474\n",
      "Epoch: 0650 cost= 0.083662257 W= 0.29544124 b= 0.47164178\n",
      "Epoch: 0700 cost= 0.082888469 W= 0.2927144 b= 0.49125788\n",
      "Epoch: 0750 cost= 0.082204200 W= 0.29014996 b= 0.5097074\n",
      "Epoch: 0800 cost= 0.081599116 W= 0.28773782 b= 0.5270596\n",
      "Epoch: 0850 cost= 0.081064075 W= 0.28546917 b= 0.54338\n",
      "Epoch: 0900 cost= 0.080590963 W= 0.2833355 b= 0.55873\n",
      "Epoch: 0950 cost= 0.080172613 W= 0.2813285 b= 0.57316774\n",
      "Epoch: 1000 cost= 0.079802744 W= 0.27944106 b= 0.5867459\n",
      "Optimization Finished!\n",
      "Training cost= 0.079802744 W= 0.27944106 b= 0.5867459 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (eager api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Eager API\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_X = [3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167,\n",
    "           7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1]\n",
    "train_Y = [1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, 1.221,\n",
    "           2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3]\n",
    "n_samples = len(train_X)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "display_step = 100\n",
    "num_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and Bias\n",
    "W = tfe.Variable(np.random.randn())\n",
    "b = tfe.Variable(np.random.randn())\n",
    "\n",
    "# Linear regression (Wx + b)\n",
    "def linear_regression(inputs):\n",
    "    return inputs * W + b\n",
    "\n",
    "# Mean square error\n",
    "def mean_square_fn(model_fn, inputs, labels):\n",
    "    return tf.reduce_sum(tf.pow(model_fn(inputs) - labels, 2)) / (2 * n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Compute gradients\n",
    "grad = tfe.implicit_gradients(mean_square_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost= 22.056007385 W= -0.6179227 b= -0.094497114\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan Wu\\Anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 0001 cost= 6.711404800 W= -0.17721999 b= -0.031399384\n",
      "Epoch: 0100 cost= 0.104648262 W= 0.3460262 b= 0.12960956\n",
      "Epoch: 0200 cost= 0.098670289 W= 0.33523065 b= 0.20614527\n",
      "Epoch: 0300 cost= 0.093981504 W= 0.32566977 b= 0.27392757\n",
      "Epoch: 0400 cost= 0.090303950 W= 0.31720236 b= 0.33395764\n",
      "Epoch: 0500 cost= 0.087419450 W= 0.30970338 b= 0.3871221\n",
      "Epoch: 0600 cost= 0.085157029 W= 0.30306205 b= 0.43420607\n",
      "Epoch: 0700 cost= 0.083382547 W= 0.2971803 b= 0.47590506\n",
      "Epoch: 0800 cost= 0.081990749 W= 0.29197127 b= 0.5128348\n",
      "Epoch: 0900 cost= 0.080899082 W= 0.28735802 b= 0.54554075\n",
      "Epoch: 1000 cost= 0.080042869 W= 0.28327236 b= 0.57450616\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initial cost, before optimizing\n",
    "print(\"Initial cost= {:.9f}\".format(\n",
    "    mean_square_fn(linear_regression, train_X, train_Y)),\n",
    "    \"W=\", W.numpy(), \"b=\", b.numpy())\n",
    "\n",
    "# Training\n",
    "for step in range(num_steps):\n",
    "\n",
    "    optimizer.apply_gradients(grad(linear_regression, train_X, train_Y))\n",
    "\n",
    "    if (step + 1) % display_step == 0 or step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (step + 1), \"cost=\",\n",
    "              \"{:.9f}\".format(mean_square_fn(linear_regression, train_X, train_Y)),\n",
    "              \"W=\", W.numpy(), \"b=\", b.numpy())\n",
    "\n",
    "# Graphic display\n",
    "plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "plt.plot(train_X, np.array(W * train_X + b), label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we limit mnist data\n",
    "Xtr, Ytr = mnist.train.next_batch(5000) #5000 for training (nn candidates)\n",
    "Xte, Yte = mnist.test.next_batch(200) #200 for testing\n",
    "\n",
    "# tf Graph Input\n",
    "xtr = tf.placeholder(\"float\", [None, 784])\n",
    "# tf.placeholder(dtype, shape=None, name=None)\n",
    "# 784是图片的像素28 * 28\n",
    "xte = tf.placeholder(\"float\", [784])\n",
    "\n",
    "# Nearest Neighbor calculation using L1 Distance\n",
    "# Calculate L1 Distance\n",
    "# 按行求和\n",
    "distance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices=1)\n",
    "# Prediction: Get min distance index (Nearest neighbor)\n",
    "pred = tf.argmin(distance, 0)# 返回矩阵横列或者纵列的最小值的坐标，取决于第二个参数 \n",
    "\n",
    "accuracy = 0.\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 Prediction: 8 True Class: 8\n",
      "Test 1 Prediction: 7 True Class: 7\n",
      "Test 2 Prediction: 0 True Class: 0\n",
      "Test 3 Prediction: 0 True Class: 0\n",
      "Test 4 Prediction: 0 True Class: 0\n",
      "Test 5 Prediction: 3 True Class: 3\n",
      "Test 6 Prediction: 0 True Class: 8\n",
      "Test 7 Prediction: 7 True Class: 7\n",
      "Test 8 Prediction: 7 True Class: 7\n",
      "Test 9 Prediction: 7 True Class: 7\n",
      "Test 10 Prediction: 0 True Class: 0\n",
      "Test 11 Prediction: 0 True Class: 0\n",
      "Test 12 Prediction: 2 True Class: 2\n",
      "Test 13 Prediction: 4 True Class: 4\n",
      "Test 14 Prediction: 8 True Class: 8\n",
      "Test 15 Prediction: 4 True Class: 4\n",
      "Test 16 Prediction: 5 True Class: 5\n",
      "Test 17 Prediction: 9 True Class: 4\n",
      "Test 18 Prediction: 6 True Class: 6\n",
      "Test 19 Prediction: 7 True Class: 7\n",
      "Test 20 Prediction: 6 True Class: 6\n",
      "Test 21 Prediction: 1 True Class: 1\n",
      "Test 22 Prediction: 0 True Class: 0\n",
      "Test 23 Prediction: 8 True Class: 8\n",
      "Test 24 Prediction: 9 True Class: 9\n",
      "Test 25 Prediction: 5 True Class: 5\n",
      "Test 26 Prediction: 0 True Class: 0\n",
      "Test 27 Prediction: 4 True Class: 4\n",
      "Test 28 Prediction: 2 True Class: 2\n",
      "Test 29 Prediction: 1 True Class: 3\n",
      "Test 30 Prediction: 0 True Class: 0\n",
      "Test 31 Prediction: 6 True Class: 6\n",
      "Test 32 Prediction: 9 True Class: 9\n",
      "Test 33 Prediction: 1 True Class: 1\n",
      "Test 34 Prediction: 7 True Class: 7\n",
      "Test 35 Prediction: 2 True Class: 2\n",
      "Test 36 Prediction: 1 True Class: 1\n",
      "Test 37 Prediction: 5 True Class: 5\n",
      "Test 38 Prediction: 3 True Class: 3\n",
      "Test 39 Prediction: 4 True Class: 4\n",
      "Test 40 Prediction: 3 True Class: 3\n",
      "Test 41 Prediction: 9 True Class: 9\n",
      "Test 42 Prediction: 6 True Class: 6\n",
      "Test 43 Prediction: 5 True Class: 5\n",
      "Test 44 Prediction: 5 True Class: 5\n",
      "Test 45 Prediction: 3 True Class: 8\n",
      "Test 46 Prediction: 9 True Class: 9\n",
      "Test 47 Prediction: 8 True Class: 8\n",
      "Test 48 Prediction: 4 True Class: 8\n",
      "Test 49 Prediction: 1 True Class: 1\n",
      "Test 50 Prediction: 8 True Class: 8\n",
      "Test 51 Prediction: 0 True Class: 0\n",
      "Test 52 Prediction: 8 True Class: 8\n",
      "Test 53 Prediction: 4 True Class: 4\n",
      "Test 54 Prediction: 9 True Class: 9\n",
      "Test 55 Prediction: 0 True Class: 0\n",
      "Test 56 Prediction: 4 True Class: 4\n",
      "Test 57 Prediction: 7 True Class: 7\n",
      "Test 58 Prediction: 3 True Class: 3\n",
      "Test 59 Prediction: 5 True Class: 5\n",
      "Test 60 Prediction: 6 True Class: 6\n",
      "Test 61 Prediction: 5 True Class: 5\n",
      "Test 62 Prediction: 3 True Class: 3\n",
      "Test 63 Prediction: 7 True Class: 7\n",
      "Test 64 Prediction: 9 True Class: 5\n",
      "Test 65 Prediction: 5 True Class: 8\n",
      "Test 66 Prediction: 3 True Class: 3\n",
      "Test 67 Prediction: 7 True Class: 7\n",
      "Test 68 Prediction: 2 True Class: 2\n",
      "Test 69 Prediction: 7 True Class: 7\n",
      "Test 70 Prediction: 8 True Class: 8\n",
      "Test 71 Prediction: 5 True Class: 5\n",
      "Test 72 Prediction: 3 True Class: 3\n",
      "Test 73 Prediction: 2 True Class: 3\n",
      "Test 74 Prediction: 1 True Class: 1\n",
      "Test 75 Prediction: 1 True Class: 1\n",
      "Test 76 Prediction: 2 True Class: 2\n",
      "Test 77 Prediction: 7 True Class: 7\n",
      "Test 78 Prediction: 8 True Class: 8\n",
      "Test 79 Prediction: 8 True Class: 8\n",
      "Test 80 Prediction: 0 True Class: 0\n",
      "Test 81 Prediction: 7 True Class: 7\n",
      "Test 82 Prediction: 0 True Class: 0\n",
      "Test 83 Prediction: 7 True Class: 7\n",
      "Test 84 Prediction: 9 True Class: 8\n",
      "Test 85 Prediction: 4 True Class: 4\n",
      "Test 86 Prediction: 9 True Class: 9\n",
      "Test 87 Prediction: 0 True Class: 0\n",
      "Test 88 Prediction: 9 True Class: 9\n",
      "Test 89 Prediction: 2 True Class: 2\n",
      "Test 90 Prediction: 9 True Class: 9\n",
      "Test 91 Prediction: 9 True Class: 9\n",
      "Test 92 Prediction: 2 True Class: 2\n",
      "Test 93 Prediction: 2 True Class: 2\n",
      "Test 94 Prediction: 1 True Class: 1\n",
      "Test 95 Prediction: 3 True Class: 3\n",
      "Test 96 Prediction: 8 True Class: 8\n",
      "Test 97 Prediction: 0 True Class: 0\n",
      "Test 98 Prediction: 6 True Class: 6\n",
      "Test 99 Prediction: 5 True Class: 5\n",
      "Test 100 Prediction: 3 True Class: 5\n",
      "Test 101 Prediction: 4 True Class: 4\n",
      "Test 102 Prediction: 0 True Class: 0\n",
      "Test 103 Prediction: 3 True Class: 3\n",
      "Test 104 Prediction: 6 True Class: 6\n",
      "Test 105 Prediction: 3 True Class: 2\n",
      "Test 106 Prediction: 7 True Class: 7\n",
      "Test 107 Prediction: 9 True Class: 9\n",
      "Test 108 Prediction: 7 True Class: 7\n",
      "Test 109 Prediction: 9 True Class: 9\n",
      "Test 110 Prediction: 2 True Class: 2\n",
      "Test 111 Prediction: 1 True Class: 1\n",
      "Test 112 Prediction: 0 True Class: 0\n",
      "Test 113 Prediction: 1 True Class: 1\n",
      "Test 114 Prediction: 5 True Class: 5\n",
      "Test 115 Prediction: 8 True Class: 8\n",
      "Test 116 Prediction: 3 True Class: 3\n",
      "Test 117 Prediction: 0 True Class: 0\n",
      "Test 118 Prediction: 7 True Class: 7\n",
      "Test 119 Prediction: 1 True Class: 1\n",
      "Test 120 Prediction: 1 True Class: 1\n",
      "Test 121 Prediction: 9 True Class: 9\n",
      "Test 122 Prediction: 8 True Class: 8\n",
      "Test 123 Prediction: 2 True Class: 2\n",
      "Test 124 Prediction: 0 True Class: 0\n",
      "Test 125 Prediction: 0 True Class: 0\n",
      "Test 126 Prediction: 8 True Class: 8\n",
      "Test 127 Prediction: 2 True Class: 2\n",
      "Test 128 Prediction: 7 True Class: 7\n",
      "Test 129 Prediction: 6 True Class: 6\n",
      "Test 130 Prediction: 8 True Class: 8\n",
      "Test 131 Prediction: 6 True Class: 6\n",
      "Test 132 Prediction: 5 True Class: 5\n",
      "Test 133 Prediction: 2 True Class: 2\n",
      "Test 134 Prediction: 0 True Class: 0\n",
      "Test 135 Prediction: 1 True Class: 1\n",
      "Test 136 Prediction: 7 True Class: 7\n",
      "Test 137 Prediction: 8 True Class: 8\n",
      "Test 138 Prediction: 0 True Class: 0\n",
      "Test 139 Prediction: 1 True Class: 3\n",
      "Test 140 Prediction: 7 True Class: 7\n",
      "Test 141 Prediction: 3 True Class: 3\n",
      "Test 142 Prediction: 1 True Class: 1\n",
      "Test 143 Prediction: 3 True Class: 3\n",
      "Test 144 Prediction: 4 True Class: 4\n",
      "Test 145 Prediction: 3 True Class: 3\n",
      "Test 146 Prediction: 2 True Class: 2\n",
      "Test 147 Prediction: 8 True Class: 8\n",
      "Test 148 Prediction: 2 True Class: 2\n",
      "Test 149 Prediction: 6 True Class: 6\n",
      "Test 150 Prediction: 2 True Class: 2\n",
      "Test 151 Prediction: 1 True Class: 1\n",
      "Test 152 Prediction: 4 True Class: 4\n",
      "Test 153 Prediction: 5 True Class: 5\n",
      "Test 154 Prediction: 2 True Class: 2\n",
      "Test 155 Prediction: 7 True Class: 7\n",
      "Test 156 Prediction: 4 True Class: 4\n",
      "Test 157 Prediction: 2 True Class: 2\n",
      "Test 158 Prediction: 5 True Class: 5\n",
      "Test 159 Prediction: 2 True Class: 2\n",
      "Test 160 Prediction: 0 True Class: 0\n",
      "Test 161 Prediction: 0 True Class: 0\n",
      "Test 162 Prediction: 1 True Class: 1\n",
      "Test 163 Prediction: 4 True Class: 9\n",
      "Test 164 Prediction: 1 True Class: 1\n",
      "Test 165 Prediction: 2 True Class: 2\n",
      "Test 166 Prediction: 6 True Class: 6\n",
      "Test 167 Prediction: 2 True Class: 1\n",
      "Test 168 Prediction: 2 True Class: 2\n",
      "Test 169 Prediction: 2 True Class: 2\n",
      "Test 170 Prediction: 2 True Class: 2\n",
      "Test 171 Prediction: 1 True Class: 1\n",
      "Test 172 Prediction: 9 True Class: 9\n",
      "Test 173 Prediction: 0 True Class: 0\n",
      "Test 174 Prediction: 3 True Class: 3\n",
      "Test 175 Prediction: 7 True Class: 7\n",
      "Test 176 Prediction: 3 True Class: 3\n",
      "Test 177 Prediction: 9 True Class: 9\n",
      "Test 178 Prediction: 0 True Class: 0\n",
      "Test 179 Prediction: 2 True Class: 2\n",
      "Test 180 Prediction: 3 True Class: 3\n",
      "Test 181 Prediction: 2 True Class: 2\n",
      "Test 182 Prediction: 0 True Class: 0\n",
      "Test 183 Prediction: 2 True Class: 2\n",
      "Test 184 Prediction: 8 True Class: 8\n",
      "Test 185 Prediction: 2 True Class: 2\n",
      "Test 186 Prediction: 5 True Class: 5\n",
      "Test 187 Prediction: 8 True Class: 8\n",
      "Test 188 Prediction: 8 True Class: 8\n",
      "Test 189 Prediction: 4 True Class: 4\n",
      "Test 190 Prediction: 3 True Class: 3\n",
      "Test 191 Prediction: 3 True Class: 3\n",
      "Test 192 Prediction: 2 True Class: 2\n",
      "Test 193 Prediction: 4 True Class: 4\n",
      "Test 194 Prediction: 0 True Class: 0\n",
      "Test 195 Prediction: 8 True Class: 8\n",
      "Test 196 Prediction: 0 True Class: 0\n",
      "Test 197 Prediction: 8 True Class: 8\n",
      "Test 198 Prediction: 5 True Class: 5\n",
      "Test 199 Prediction: 6 True Class: 6\n",
      "Done!\n",
      "Accuracy: 0.9300000000000007\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # loop over test data\n",
    "    for i in range(len(Xte)):\n",
    "        # Get nearest neighbor\n",
    "        nn_index = sess.run(pred, feed_dict={xtr: Xtr, xte: Xte[i, :]})\n",
    "        # Get nearest neighbor class label and compare it to its true label\n",
    "        print(\"Test\", i, \"Prediction:\", np.argmax(Ytr[nn_index]), \\\n",
    "            \"True Class:\", np.argmax(Yte[i]))\n",
    "        # Calculate accuracy\n",
    "        if np.argmax(Ytr[nn_index]) == np.argmax(Yte[i]):\n",
    "            accuracy += 1./len(Xte)\n",
    "    print(\"Done!\")\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.factorization import KMeans\n",
    "\n",
    "# Ignore all GPUs, tf random forest does not benefit from it.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 19:59:43.088595  7632 deprecation.py:323] From <ipython-input-5-2c0b2b4ed230>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0909 19:59:43.089621  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0909 19:59:43.090589  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "W0909 19:59:57.435160  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 20:00:00.650134  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0909 20:00:00.655082  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 20:00:08.630361  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "full_data_x = mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_steps = 50 # Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "k = 50 # The number of clusters\n",
    "num_classes = 10 # The 10 digits\n",
    "num_features = 784 # Each image is 28x28 pixels\n",
    "\n",
    "# Input images\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "# Labels (for assigning a label to a centroid and testing)\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "\n",
    "# K-Means Parameters\n",
    "kmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine',\n",
    "                use_mini_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KMeans graph\n",
    "(all_scores, cluster_idx, scores, cluster_centers_initialized, \n",
    "init_op,train_op) = kmeans.training_graph()\n",
    "cluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\n",
    "avg_distance = tf.reduce_mean(scores)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init_vars = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Avg Distance: 0.314557\n",
      "Step 10, Avg Distance: 0.198181\n",
      "Step 20, Avg Distance: 0.196513\n",
      "Step 30, Avg Distance: 0.195821\n",
      "Step 40, Avg Distance: 0.195415\n",
      "Step 50, Avg Distance: 0.195135\n"
     ]
    }
   ],
   "source": [
    "# Start TensorFlow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init_vars, feed_dict={X: full_data_x})\n",
    "sess.run(init_op, feed_dict={X: full_data_x})\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps + 1):\n",
    "    _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n",
    "                         feed_dict={X: full_data_x})\n",
    "    if i % 10 == 0 or i == 1:\n",
    "        print(\"Step %i, Avg Distance: %f\" % (i, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8074\n"
     ]
    }
   ],
   "source": [
    "# Assign a label to each centroid\n",
    "# Count total number of labels per centroid, using the label of each training\n",
    "# sample to their closest centroid (given by 'idx')\n",
    "counts = np.zeros(shape=(k, num_classes))\n",
    "for i in range(len(idx)):\n",
    "    counts[idx[i]] += mnist.train.labels[i]\n",
    "# Assign the most frequent label to the centroid\n",
    "labels_map = [np.argmax(c) for c in counts]\n",
    "labels_map = tf.convert_to_tensor(labels_map)\n",
    "\n",
    "# Evaluation ops\n",
    "# Lookup: centroid_id -> label\n",
    "cluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n",
    "# Compute accuracy\n",
    "correct_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Test Model\n",
    "test_x, test_y = mnist.test.images, mnist.test.labels\n",
    "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import resources\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "\n",
    "# Ignore all GPUs, tf random forest does not benefit from it.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "num_steps = 500 # Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "num_classes = 10 # The 10 digits\n",
    "num_features = 784 # Each image is 28x28 pixels\n",
    "num_trees = 10\n",
    "max_nodes = 1000\n",
    "\n",
    "# Input and Target data\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "# For random forest, labels must be integers (the class id)\n",
    "Y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "# Random Forest Parameters\n",
    "hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=num_trees,\n",
    "                                      max_nodes=max_nodes).fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 22:18:37.631386  7632 deprecation.py:506] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 22:18:37.841825  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\tensor_forest.py:529: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# Build the Random Forest\n",
    "forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "# Get training graph and loss\n",
    "train_op = forest_graph.training_graph(X, Y)\n",
    "loss_op = forest_graph.training_loss(X, Y)\n",
    "\n",
    "# Measure the accuracy\n",
    "infer_op, _, _ = forest_graph.inference_graph(X)\n",
    "correct_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value) and forest resources\n",
    "init_vars = tf.group(tf.global_variables_initializer(),\n",
    "    resources.initialize_resources(resources.shared_resources()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 22:20:13.536843  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss: -1.200000, Acc: 0.408203\n",
      "Step 50, Loss: -256.600006, Acc: 0.889648\n",
      "Step 100, Loss: -541.000000, Acc: 0.929688\n",
      "Step 150, Loss: -832.599976, Acc: 0.916992\n",
      "Step 200, Loss: -1001.000000, Acc: 0.926758\n",
      "Step 250, Loss: -1001.000000, Acc: 0.924805\n",
      "Step 300, Loss: -1001.000000, Acc: 0.940430\n",
      "Step 350, Loss: -1001.000000, Acc: 0.931641\n",
      "Step 400, Loss: -1001.000000, Acc: 0.930664\n",
      "Step 450, Loss: -1001.000000, Acc: 0.928711\n",
      "Step 500, Loss: -1001.000000, Acc: 0.923828\n",
      "Test Accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "# Start TensorFlow session\n",
    "sess = tf.train.MonitoredSession()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init_vars)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps + 1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "    if i % 50 == 0 or i == 1:\n",
    "        acc = sess.run(accuracy_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n",
    "\n",
    "# Test Model\n",
    "test_x, test_y = mnist.test.images, mnist.test.labels\n",
    "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier\n",
    "from tensorflow.contrib.boosted_trees.proto import learner_pb2 as gbdt_learner\n",
    "\n",
    "# Ignore all GPUs (current TF GBDT does not support GPU).\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "# Set verbosity to display errors only (Remove this line for showing warnings)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False,\n",
    "                                  source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 4096 # The number of samples per batch\n",
    "num_classes = 10 # The 10 digits\n",
    "num_features = 784 # Each image is 28x28 pixels\n",
    "max_steps = 10000\n",
    "\n",
    "# GBDT Parameters\n",
    "learning_rate = 0.1\n",
    "l1_regul = 0.\n",
    "l2_regul = 1.\n",
    "examples_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill GBDT parameters into the config proto\n",
    "learner_config = gbdt_learner.LearnerConfig()\n",
    "learner_config.learning_rate_tuner.fixed.learning_rate = learning_rate\n",
    "learner_config.regularization.l1 = l1_regul\n",
    "learner_config.regularization.l2 = l2_regul / examples_per_layer\n",
    "learner_config.constraints.max_tree_depth = max_depth\n",
    "growing_mode = gbdt_learner.LearnerConfig.LAYER_BY_LAYER\n",
    "learner_config.growing_mode = growing_mode\n",
    "run_config = tf.contrib.learn.RunConfig(save_checkpoints_secs=300)\n",
    "learner_config.multi_class_strategy = (\n",
    "    gbdt_learner.LearnerConfig.DIAGONAL_HESSIAN)\n",
    "\n",
    "# Create a TensorFlor GBDT Estimator\n",
    "gbdt_model = GradientBoostedDecisionTreeClassifier(\n",
    "    model_dir=None, # No save directory specified\n",
    "    learner_config=learner_config,\n",
    "    n_classes=num_classes,\n",
    "    examples_per_layer=examples_per_layer,\n",
    "    num_trees=num_trees,\n",
    "    center_bias=False,\n",
    "    config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 22:39:38.871496  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0909 22:39:38.873490  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0909 22:39:38.883465  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "I0909 22:39:39.968562  7632 gbdt_batch.py:437] Active Feature Columns: ['images_0', 'images_1', 'images_2', 'images_3', 'images_4', 'images_5', 'images_6', 'images_7', 'images_8', 'images_9', 'images_10', 'images_11', 'images_12', 'images_13', 'images_14', 'images_15', 'images_16', 'images_17', 'images_18', 'images_19', 'images_20', 'images_21', 'images_22', 'images_23', 'images_24', 'images_25', 'images_26', 'images_27', 'images_28', 'images_29', 'images_30', 'images_31', 'images_32', 'images_33', 'images_34', 'images_35', 'images_36', 'images_37', 'images_38', 'images_39', 'images_40', 'images_41', 'images_42', 'images_43', 'images_44', 'images_45', 'images_46', 'images_47', 'images_48', 'images_49', 'images_50', 'images_51', 'images_52', 'images_53', 'images_54', 'images_55', 'images_56', 'images_57', 'images_58', 'images_59', 'images_60', 'images_61', 'images_62', 'images_63', 'images_64', 'images_65', 'images_66', 'images_67', 'images_68', 'images_69', 'images_70', 'images_71', 'images_72', 'images_73', 'images_74', 'images_75', 'images_76', 'images_77', 'images_78', 'images_79', 'images_80', 'images_81', 'images_82', 'images_83', 'images_84', 'images_85', 'images_86', 'images_87', 'images_88', 'images_89', 'images_90', 'images_91', 'images_92', 'images_93', 'images_94', 'images_95', 'images_96', 'images_97', 'images_98', 'images_99', 'images_100', 'images_101', 'images_102', 'images_103', 'images_104', 'images_105', 'images_106', 'images_107', 'images_108', 'images_109', 'images_110', 'images_111', 'images_112', 'images_113', 'images_114', 'images_115', 'images_116', 'images_117', 'images_118', 'images_119', 'images_120', 'images_121', 'images_122', 'images_123', 'images_124', 'images_125', 'images_126', 'images_127', 'images_128', 'images_129', 'images_130', 'images_131', 'images_132', 'images_133', 'images_134', 'images_135', 'images_136', 'images_137', 'images_138', 'images_139', 'images_140', 'images_141', 'images_142', 'images_143', 'images_144', 'images_145', 'images_146', 'images_147', 'images_148', 'images_149', 'images_150', 'images_151', 'images_152', 'images_153', 'images_154', 'images_155', 'images_156', 'images_157', 'images_158', 'images_159', 'images_160', 'images_161', 'images_162', 'images_163', 'images_164', 'images_165', 'images_166', 'images_167', 'images_168', 'images_169', 'images_170', 'images_171', 'images_172', 'images_173', 'images_174', 'images_175', 'images_176', 'images_177', 'images_178', 'images_179', 'images_180', 'images_181', 'images_182', 'images_183', 'images_184', 'images_185', 'images_186', 'images_187', 'images_188', 'images_189', 'images_190', 'images_191', 'images_192', 'images_193', 'images_194', 'images_195', 'images_196', 'images_197', 'images_198', 'images_199', 'images_200', 'images_201', 'images_202', 'images_203', 'images_204', 'images_205', 'images_206', 'images_207', 'images_208', 'images_209', 'images_210', 'images_211', 'images_212', 'images_213', 'images_214', 'images_215', 'images_216', 'images_217', 'images_218', 'images_219', 'images_220', 'images_221', 'images_222', 'images_223', 'images_224', 'images_225', 'images_226', 'images_227', 'images_228', 'images_229', 'images_230', 'images_231', 'images_232', 'images_233', 'images_234', 'images_235', 'images_236', 'images_237', 'images_238', 'images_239', 'images_240', 'images_241', 'images_242', 'images_243', 'images_244', 'images_245', 'images_246', 'images_247', 'images_248', 'images_249', 'images_250', 'images_251', 'images_252', 'images_253', 'images_254', 'images_255', 'images_256', 'images_257', 'images_258', 'images_259', 'images_260', 'images_261', 'images_262', 'images_263', 'images_264', 'images_265', 'images_266', 'images_267', 'images_268', 'images_269', 'images_270', 'images_271', 'images_272', 'images_273', 'images_274', 'images_275', 'images_276', 'images_277', 'images_278', 'images_279', 'images_280', 'images_281', 'images_282', 'images_283', 'images_284', 'images_285', 'images_286', 'images_287', 'images_288', 'images_289', 'images_290', 'images_291', 'images_292', 'images_293', 'images_294', 'images_295', 'images_296', 'images_297', 'images_298', 'images_299', 'images_300', 'images_301', 'images_302', 'images_303', 'images_304', 'images_305', 'images_306', 'images_307', 'images_308', 'images_309', 'images_310', 'images_311', 'images_312', 'images_313', 'images_314', 'images_315', 'images_316', 'images_317', 'images_318', 'images_319', 'images_320', 'images_321', 'images_322', 'images_323', 'images_324', 'images_325', 'images_326', 'images_327', 'images_328', 'images_329', 'images_330', 'images_331', 'images_332', 'images_333', 'images_334', 'images_335', 'images_336', 'images_337', 'images_338', 'images_339', 'images_340', 'images_341', 'images_342', 'images_343', 'images_344', 'images_345', 'images_346', 'images_347', 'images_348', 'images_349', 'images_350', 'images_351', 'images_352', 'images_353', 'images_354', 'images_355', 'images_356', 'images_357', 'images_358', 'images_359', 'images_360', 'images_361', 'images_362', 'images_363', 'images_364', 'images_365', 'images_366', 'images_367', 'images_368', 'images_369', 'images_370', 'images_371', 'images_372', 'images_373', 'images_374', 'images_375', 'images_376', 'images_377', 'images_378', 'images_379', 'images_380', 'images_381', 'images_382', 'images_383', 'images_384', 'images_385', 'images_386', 'images_387', 'images_388', 'images_389', 'images_390', 'images_391', 'images_392', 'images_393', 'images_394', 'images_395', 'images_396', 'images_397', 'images_398', 'images_399', 'images_400', 'images_401', 'images_402', 'images_403', 'images_404', 'images_405', 'images_406', 'images_407', 'images_408', 'images_409', 'images_410', 'images_411', 'images_412', 'images_413', 'images_414', 'images_415', 'images_416', 'images_417', 'images_418', 'images_419', 'images_420', 'images_421', 'images_422', 'images_423', 'images_424', 'images_425', 'images_426', 'images_427', 'images_428', 'images_429', 'images_430', 'images_431', 'images_432', 'images_433', 'images_434', 'images_435', 'images_436', 'images_437', 'images_438', 'images_439', 'images_440', 'images_441', 'images_442', 'images_443', 'images_444', 'images_445', 'images_446', 'images_447', 'images_448', 'images_449', 'images_450', 'images_451', 'images_452', 'images_453', 'images_454', 'images_455', 'images_456', 'images_457', 'images_458', 'images_459', 'images_460', 'images_461', 'images_462', 'images_463', 'images_464', 'images_465', 'images_466', 'images_467', 'images_468', 'images_469', 'images_470', 'images_471', 'images_472', 'images_473', 'images_474', 'images_475', 'images_476', 'images_477', 'images_478', 'images_479', 'images_480', 'images_481', 'images_482', 'images_483', 'images_484', 'images_485', 'images_486', 'images_487', 'images_488', 'images_489', 'images_490', 'images_491', 'images_492', 'images_493', 'images_494', 'images_495', 'images_496', 'images_497', 'images_498', 'images_499', 'images_500', 'images_501', 'images_502', 'images_503', 'images_504', 'images_505', 'images_506', 'images_507', 'images_508', 'images_509', 'images_510', 'images_511', 'images_512', 'images_513', 'images_514', 'images_515', 'images_516', 'images_517', 'images_518', 'images_519', 'images_520', 'images_521', 'images_522', 'images_523', 'images_524', 'images_525', 'images_526', 'images_527', 'images_528', 'images_529', 'images_530', 'images_531', 'images_532', 'images_533', 'images_534', 'images_535', 'images_536', 'images_537', 'images_538', 'images_539', 'images_540', 'images_541', 'images_542', 'images_543', 'images_544', 'images_545', 'images_546', 'images_547', 'images_548', 'images_549', 'images_550', 'images_551', 'images_552', 'images_553', 'images_554', 'images_555', 'images_556', 'images_557', 'images_558', 'images_559', 'images_560', 'images_561', 'images_562', 'images_563', 'images_564', 'images_565', 'images_566', 'images_567', 'images_568', 'images_569', 'images_570', 'images_571', 'images_572', 'images_573', 'images_574', 'images_575', 'images_576', 'images_577', 'images_578', 'images_579', 'images_580', 'images_581', 'images_582', 'images_583', 'images_584', 'images_585', 'images_586', 'images_587', 'images_588', 'images_589', 'images_590', 'images_591', 'images_592', 'images_593', 'images_594', 'images_595', 'images_596', 'images_597', 'images_598', 'images_599', 'images_600', 'images_601', 'images_602', 'images_603', 'images_604', 'images_605', 'images_606', 'images_607', 'images_608', 'images_609', 'images_610', 'images_611', 'images_612', 'images_613', 'images_614', 'images_615', 'images_616', 'images_617', 'images_618', 'images_619', 'images_620', 'images_621', 'images_622', 'images_623', 'images_624', 'images_625', 'images_626', 'images_627', 'images_628', 'images_629', 'images_630', 'images_631', 'images_632', 'images_633', 'images_634', 'images_635', 'images_636', 'images_637', 'images_638', 'images_639', 'images_640', 'images_641', 'images_642', 'images_643', 'images_644', 'images_645', 'images_646', 'images_647', 'images_648', 'images_649', 'images_650', 'images_651', 'images_652', 'images_653', 'images_654', 'images_655', 'images_656', 'images_657', 'images_658', 'images_659', 'images_660', 'images_661', 'images_662', 'images_663', 'images_664', 'images_665', 'images_666', 'images_667', 'images_668', 'images_669', 'images_670', 'images_671', 'images_672', 'images_673', 'images_674', 'images_675', 'images_676', 'images_677', 'images_678', 'images_679', 'images_680', 'images_681', 'images_682', 'images_683', 'images_684', 'images_685', 'images_686', 'images_687', 'images_688', 'images_689', 'images_690', 'images_691', 'images_692', 'images_693', 'images_694', 'images_695', 'images_696', 'images_697', 'images_698', 'images_699', 'images_700', 'images_701', 'images_702', 'images_703', 'images_704', 'images_705', 'images_706', 'images_707', 'images_708', 'images_709', 'images_710', 'images_711', 'images_712', 'images_713', 'images_714', 'images_715', 'images_716', 'images_717', 'images_718', 'images_719', 'images_720', 'images_721', 'images_722', 'images_723', 'images_724', 'images_725', 'images_726', 'images_727', 'images_728', 'images_729', 'images_730', 'images_731', 'images_732', 'images_733', 'images_734', 'images_735', 'images_736', 'images_737', 'images_738', 'images_739', 'images_740', 'images_741', 'images_742', 'images_743', 'images_744', 'images_745', 'images_746', 'images_747', 'images_748', 'images_749', 'images_750', 'images_751', 'images_752', 'images_753', 'images_754', 'images_755', 'images_756', 'images_757', 'images_758', 'images_759', 'images_760', 'images_761', 'images_762', 'images_763', 'images_764', 'images_765', 'images_766', 'images_767', 'images_768', 'images_769', 'images_770', 'images_771', 'images_772', 'images_773', 'images_774', 'images_775', 'images_776', 'images_777', 'images_778', 'images_779', 'images_780', 'images_781', 'images_782', 'images_783']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0909 22:39:39.969560  7632 gbdt_batch.py:438] Learner config: num_classes: 10\n",
      "regularization {\n",
      "  l2: 0.0010000000474974513\n",
      "}\n",
      "constraints {\n",
      "  max_tree_depth: 16\n",
      "}\n",
      "learning_rate_tuner {\n",
      "  fixed {\n",
      "    learning_rate: 0.10000000149011612\n",
      "  }\n",
      "}\n",
      "pruning_mode: POST_PRUNE\n",
      "growing_mode: LAYER_BY_LAYER\n",
      "multi_class_strategy: DIAGONAL_HESSIAN\n",
      "\n",
      "W0909 22:39:56.790055  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "I0909 22:39:56.791061  7632 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "W0909 22:39:59.231551  7632 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "I0909 22:40:04.212332  7632 monitored_session.py:240] Graph was finalized.\n",
      "I0909 22:40:07.800759  7632 session_manager.py:500] Running local_init_op.\n",
      "I0909 22:40:08.170770  7632 session_manager.py:502] Done running local_init_op.\n",
      "W0909 22:40:09.320778  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0909 22:40:22.988695  7632 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "I0909 22:40:24.557026  7632 basic_session_run_hooks.py:606] Saving checkpoints for 0 into C:\\Users\\MR5E8F~1.WU\\AppData\\Local\\Temp\\tmppf1qujhw\\model.ckpt.\n",
      "W0909 22:40:27.350595  7632 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "I0909 22:40:50.256408  7632 basic_session_run_hooks.py:262] loss = 2.3025992, step = 1\n",
      "I0909 22:45:29.138280  7632 basic_session_run_hooks.py:606] Saving checkpoints for 81 into C:\\Users\\MR5E8F~1.WU\\AppData\\Local\\Temp\\tmppf1qujhw\\model.ckpt.\n",
      "W0909 22:45:30.336069  7632 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "I0909 22:46:30.419008  7632 basic_session_run_hooks.py:692] global_step/sec: 0.293976\n",
      "I0909 22:46:30.421002  7632 basic_session_run_hooks.py:260] loss = 0.3019178, step = 101 (340.164 sec)\n",
      "I0909 22:50:11.313240  7632 trainer_hooks.py:189] Requesting stop since we have reached 10 trees.\n",
      "I0909 22:50:11.317228  7632 basic_session_run_hooks.py:606] Saving checkpoints for 161 into C:\\Users\\MR5E8F~1.WU\\AppData\\Local\\Temp\\tmppf1qujhw\\model.ckpt.\n",
      "W0909 22:50:13.103505  7632 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "I0909 22:50:15.179462  7632 estimator.py:525] Loss for final step: 0.22175708.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostedDecisionTreeClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001BCD1E42278>, 'feature_columns': None, 'learner_config': num_classes: 10\n",
       "regularization {\n",
       "  l2: 0.0010000000474974513\n",
       "}\n",
       "constraints {\n",
       "  max_tree_depth: 16\n",
       "}\n",
       "learning_rate_tuner {\n",
       "  fixed {\n",
       "    learning_rate: 0.10000000149011612\n",
       "  }\n",
       "}\n",
       "pruning_mode: POST_PRUNE\n",
       "growing_mode: LAYER_BY_LAYER\n",
       "multi_class_strategy: DIAGONAL_HESSIAN\n",
       ", 'num_trees': 10, 'weight_column_name': None, 'examples_per_layer': 1000, 'center_bias': False, 'logits_modifier_function': None, 'use_core_libs': False, 'output_leaf_index': False, 'override_global_step_value': None, 'num_quantiles': 100})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display TF info logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "gbdt_model.fit(input_fn=input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0909 22:50:16.224694  7632 gbdt_batch.py:437] Active Feature Columns: ['images_0', 'images_1', 'images_2', 'images_3', 'images_4', 'images_5', 'images_6', 'images_7', 'images_8', 'images_9', 'images_10', 'images_11', 'images_12', 'images_13', 'images_14', 'images_15', 'images_16', 'images_17', 'images_18', 'images_19', 'images_20', 'images_21', 'images_22', 'images_23', 'images_24', 'images_25', 'images_26', 'images_27', 'images_28', 'images_29', 'images_30', 'images_31', 'images_32', 'images_33', 'images_34', 'images_35', 'images_36', 'images_37', 'images_38', 'images_39', 'images_40', 'images_41', 'images_42', 'images_43', 'images_44', 'images_45', 'images_46', 'images_47', 'images_48', 'images_49', 'images_50', 'images_51', 'images_52', 'images_53', 'images_54', 'images_55', 'images_56', 'images_57', 'images_58', 'images_59', 'images_60', 'images_61', 'images_62', 'images_63', 'images_64', 'images_65', 'images_66', 'images_67', 'images_68', 'images_69', 'images_70', 'images_71', 'images_72', 'images_73', 'images_74', 'images_75', 'images_76', 'images_77', 'images_78', 'images_79', 'images_80', 'images_81', 'images_82', 'images_83', 'images_84', 'images_85', 'images_86', 'images_87', 'images_88', 'images_89', 'images_90', 'images_91', 'images_92', 'images_93', 'images_94', 'images_95', 'images_96', 'images_97', 'images_98', 'images_99', 'images_100', 'images_101', 'images_102', 'images_103', 'images_104', 'images_105', 'images_106', 'images_107', 'images_108', 'images_109', 'images_110', 'images_111', 'images_112', 'images_113', 'images_114', 'images_115', 'images_116', 'images_117', 'images_118', 'images_119', 'images_120', 'images_121', 'images_122', 'images_123', 'images_124', 'images_125', 'images_126', 'images_127', 'images_128', 'images_129', 'images_130', 'images_131', 'images_132', 'images_133', 'images_134', 'images_135', 'images_136', 'images_137', 'images_138', 'images_139', 'images_140', 'images_141', 'images_142', 'images_143', 'images_144', 'images_145', 'images_146', 'images_147', 'images_148', 'images_149', 'images_150', 'images_151', 'images_152', 'images_153', 'images_154', 'images_155', 'images_156', 'images_157', 'images_158', 'images_159', 'images_160', 'images_161', 'images_162', 'images_163', 'images_164', 'images_165', 'images_166', 'images_167', 'images_168', 'images_169', 'images_170', 'images_171', 'images_172', 'images_173', 'images_174', 'images_175', 'images_176', 'images_177', 'images_178', 'images_179', 'images_180', 'images_181', 'images_182', 'images_183', 'images_184', 'images_185', 'images_186', 'images_187', 'images_188', 'images_189', 'images_190', 'images_191', 'images_192', 'images_193', 'images_194', 'images_195', 'images_196', 'images_197', 'images_198', 'images_199', 'images_200', 'images_201', 'images_202', 'images_203', 'images_204', 'images_205', 'images_206', 'images_207', 'images_208', 'images_209', 'images_210', 'images_211', 'images_212', 'images_213', 'images_214', 'images_215', 'images_216', 'images_217', 'images_218', 'images_219', 'images_220', 'images_221', 'images_222', 'images_223', 'images_224', 'images_225', 'images_226', 'images_227', 'images_228', 'images_229', 'images_230', 'images_231', 'images_232', 'images_233', 'images_234', 'images_235', 'images_236', 'images_237', 'images_238', 'images_239', 'images_240', 'images_241', 'images_242', 'images_243', 'images_244', 'images_245', 'images_246', 'images_247', 'images_248', 'images_249', 'images_250', 'images_251', 'images_252', 'images_253', 'images_254', 'images_255', 'images_256', 'images_257', 'images_258', 'images_259', 'images_260', 'images_261', 'images_262', 'images_263', 'images_264', 'images_265', 'images_266', 'images_267', 'images_268', 'images_269', 'images_270', 'images_271', 'images_272', 'images_273', 'images_274', 'images_275', 'images_276', 'images_277', 'images_278', 'images_279', 'images_280', 'images_281', 'images_282', 'images_283', 'images_284', 'images_285', 'images_286', 'images_287', 'images_288', 'images_289', 'images_290', 'images_291', 'images_292', 'images_293', 'images_294', 'images_295', 'images_296', 'images_297', 'images_298', 'images_299', 'images_300', 'images_301', 'images_302', 'images_303', 'images_304', 'images_305', 'images_306', 'images_307', 'images_308', 'images_309', 'images_310', 'images_311', 'images_312', 'images_313', 'images_314', 'images_315', 'images_316', 'images_317', 'images_318', 'images_319', 'images_320', 'images_321', 'images_322', 'images_323', 'images_324', 'images_325', 'images_326', 'images_327', 'images_328', 'images_329', 'images_330', 'images_331', 'images_332', 'images_333', 'images_334', 'images_335', 'images_336', 'images_337', 'images_338', 'images_339', 'images_340', 'images_341', 'images_342', 'images_343', 'images_344', 'images_345', 'images_346', 'images_347', 'images_348', 'images_349', 'images_350', 'images_351', 'images_352', 'images_353', 'images_354', 'images_355', 'images_356', 'images_357', 'images_358', 'images_359', 'images_360', 'images_361', 'images_362', 'images_363', 'images_364', 'images_365', 'images_366', 'images_367', 'images_368', 'images_369', 'images_370', 'images_371', 'images_372', 'images_373', 'images_374', 'images_375', 'images_376', 'images_377', 'images_378', 'images_379', 'images_380', 'images_381', 'images_382', 'images_383', 'images_384', 'images_385', 'images_386', 'images_387', 'images_388', 'images_389', 'images_390', 'images_391', 'images_392', 'images_393', 'images_394', 'images_395', 'images_396', 'images_397', 'images_398', 'images_399', 'images_400', 'images_401', 'images_402', 'images_403', 'images_404', 'images_405', 'images_406', 'images_407', 'images_408', 'images_409', 'images_410', 'images_411', 'images_412', 'images_413', 'images_414', 'images_415', 'images_416', 'images_417', 'images_418', 'images_419', 'images_420', 'images_421', 'images_422', 'images_423', 'images_424', 'images_425', 'images_426', 'images_427', 'images_428', 'images_429', 'images_430', 'images_431', 'images_432', 'images_433', 'images_434', 'images_435', 'images_436', 'images_437', 'images_438', 'images_439', 'images_440', 'images_441', 'images_442', 'images_443', 'images_444', 'images_445', 'images_446', 'images_447', 'images_448', 'images_449', 'images_450', 'images_451', 'images_452', 'images_453', 'images_454', 'images_455', 'images_456', 'images_457', 'images_458', 'images_459', 'images_460', 'images_461', 'images_462', 'images_463', 'images_464', 'images_465', 'images_466', 'images_467', 'images_468', 'images_469', 'images_470', 'images_471', 'images_472', 'images_473', 'images_474', 'images_475', 'images_476', 'images_477', 'images_478', 'images_479', 'images_480', 'images_481', 'images_482', 'images_483', 'images_484', 'images_485', 'images_486', 'images_487', 'images_488', 'images_489', 'images_490', 'images_491', 'images_492', 'images_493', 'images_494', 'images_495', 'images_496', 'images_497', 'images_498', 'images_499', 'images_500', 'images_501', 'images_502', 'images_503', 'images_504', 'images_505', 'images_506', 'images_507', 'images_508', 'images_509', 'images_510', 'images_511', 'images_512', 'images_513', 'images_514', 'images_515', 'images_516', 'images_517', 'images_518', 'images_519', 'images_520', 'images_521', 'images_522', 'images_523', 'images_524', 'images_525', 'images_526', 'images_527', 'images_528', 'images_529', 'images_530', 'images_531', 'images_532', 'images_533', 'images_534', 'images_535', 'images_536', 'images_537', 'images_538', 'images_539', 'images_540', 'images_541', 'images_542', 'images_543', 'images_544', 'images_545', 'images_546', 'images_547', 'images_548', 'images_549', 'images_550', 'images_551', 'images_552', 'images_553', 'images_554', 'images_555', 'images_556', 'images_557', 'images_558', 'images_559', 'images_560', 'images_561', 'images_562', 'images_563', 'images_564', 'images_565', 'images_566', 'images_567', 'images_568', 'images_569', 'images_570', 'images_571', 'images_572', 'images_573', 'images_574', 'images_575', 'images_576', 'images_577', 'images_578', 'images_579', 'images_580', 'images_581', 'images_582', 'images_583', 'images_584', 'images_585', 'images_586', 'images_587', 'images_588', 'images_589', 'images_590', 'images_591', 'images_592', 'images_593', 'images_594', 'images_595', 'images_596', 'images_597', 'images_598', 'images_599', 'images_600', 'images_601', 'images_602', 'images_603', 'images_604', 'images_605', 'images_606', 'images_607', 'images_608', 'images_609', 'images_610', 'images_611', 'images_612', 'images_613', 'images_614', 'images_615', 'images_616', 'images_617', 'images_618', 'images_619', 'images_620', 'images_621', 'images_622', 'images_623', 'images_624', 'images_625', 'images_626', 'images_627', 'images_628', 'images_629', 'images_630', 'images_631', 'images_632', 'images_633', 'images_634', 'images_635', 'images_636', 'images_637', 'images_638', 'images_639', 'images_640', 'images_641', 'images_642', 'images_643', 'images_644', 'images_645', 'images_646', 'images_647', 'images_648', 'images_649', 'images_650', 'images_651', 'images_652', 'images_653', 'images_654', 'images_655', 'images_656', 'images_657', 'images_658', 'images_659', 'images_660', 'images_661', 'images_662', 'images_663', 'images_664', 'images_665', 'images_666', 'images_667', 'images_668', 'images_669', 'images_670', 'images_671', 'images_672', 'images_673', 'images_674', 'images_675', 'images_676', 'images_677', 'images_678', 'images_679', 'images_680', 'images_681', 'images_682', 'images_683', 'images_684', 'images_685', 'images_686', 'images_687', 'images_688', 'images_689', 'images_690', 'images_691', 'images_692', 'images_693', 'images_694', 'images_695', 'images_696', 'images_697', 'images_698', 'images_699', 'images_700', 'images_701', 'images_702', 'images_703', 'images_704', 'images_705', 'images_706', 'images_707', 'images_708', 'images_709', 'images_710', 'images_711', 'images_712', 'images_713', 'images_714', 'images_715', 'images_716', 'images_717', 'images_718', 'images_719', 'images_720', 'images_721', 'images_722', 'images_723', 'images_724', 'images_725', 'images_726', 'images_727', 'images_728', 'images_729', 'images_730', 'images_731', 'images_732', 'images_733', 'images_734', 'images_735', 'images_736', 'images_737', 'images_738', 'images_739', 'images_740', 'images_741', 'images_742', 'images_743', 'images_744', 'images_745', 'images_746', 'images_747', 'images_748', 'images_749', 'images_750', 'images_751', 'images_752', 'images_753', 'images_754', 'images_755', 'images_756', 'images_757', 'images_758', 'images_759', 'images_760', 'images_761', 'images_762', 'images_763', 'images_764', 'images_765', 'images_766', 'images_767', 'images_768', 'images_769', 'images_770', 'images_771', 'images_772', 'images_773', 'images_774', 'images_775', 'images_776', 'images_777', 'images_778', 'images_779', 'images_780', 'images_781', 'images_782', 'images_783']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0909 22:50:16.225691  7632 gbdt_batch.py:438] Learner config: num_classes: 10\n",
      "regularization {\n",
      "  l2: 0.0010000000474974513\n",
      "}\n",
      "constraints {\n",
      "  max_tree_depth: 16\n",
      "}\n",
      "learning_rate_tuner {\n",
      "  fixed {\n",
      "    learning_rate: 0.10000000149011612\n",
      "  }\n",
      "}\n",
      "pruning_mode: POST_PRUNE\n",
      "growing_mode: LAYER_BY_LAYER\n",
      "multi_class_strategy: DIAGONAL_HESSIAN\n",
      "\n",
      "I0909 22:50:16.321434  7632 evaluation.py:255] Starting evaluation at 2019-09-09T22:50:16Z\n",
      "I0909 22:50:16.421168  7632 monitored_session.py:240] Graph was finalized.\n",
      "W0909 22:50:16.422166  7632 deprecation.py:323] From C:\\Users\\Mr. Wu\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0909 22:50:16.428186  7632 saver.py:1280] Restoring parameters from C:\\Users\\MR5E8F~1.WU\\AppData\\Local\\Temp\\tmppf1qujhw\\model.ckpt-161\n",
      "I0909 22:50:16.515915  7632 session_manager.py:500] Running local_init_op.\n",
      "I0909 22:50:16.536859  7632 session_manager.py:502] Done running local_init_op.\n",
      "I0909 22:50:17.276421  7632 evaluation.py:275] Finished evaluation at 2019-09-09-22:50:17\n",
      "I0909 22:50:17.277390  7632 estimator.py:347] Saving dict for global step 161: accuracy = 0.9287, global_step = 161, loss = 0.24334426\n",
      "W0909 22:50:17.459919  7632 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9287\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = gbdt_model.evaluate(input_fn=input_fn)\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
